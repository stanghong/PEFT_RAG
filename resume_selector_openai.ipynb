{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/htang/Documents/amazon-bedrock-rag-workshop/bedragenv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "\n",
    "def read_pdf2Text(pdf_directory, pdf_filenames):\n",
    "    extracted_texts = {}\n",
    "    for filename in pdf_filenames:\n",
    "        pdf_path = os.path.join(pdf_directory, filename)\n",
    "        with fitz.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf:\n",
    "                text += page.get_text()\n",
    "            extracted_texts[filename] = text\n",
    "    return extracted_texts\n",
    "\n",
    "# Define the directory containing the PDFs\n",
    "pdf_directory = './data'\n",
    "\n",
    "# Read all file names in the pdf_directory that end with '.pdf'\n",
    "pdf_filenames = [f for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
    "\n",
    "\n",
    "extracted_texts=read_pdf2Text(pdf_directory, pdf_filenames)\n",
    "# Return the number of extracted texts to confirm extraction\n",
    "len(extracted_texts)\n",
    "\n",
    "pdf_filename=['search_resume.pdf']\n",
    "pdf_directory='.'\n",
    "new_resume_content =read_pdf2Text(pdf_directory, pdf_filename)\n",
    "len(new_resume_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Engineer Resume\\nContact Information\\nName: Jordan Smith\\nAddress: 500 Tech Avenue, Techville, USA\\nPhone: (555) 500-5000\\nEmail: jordan.smith@example.com\\nLinkedIn: linkedin.com/in/jordansmith\\nGitHub: github.com/jordansmith\\nMachine Learning Engineer Resume\\nProfessional Summary\\nInnovative and results-driven Machine Learning Engineer with over three years of experience in\\ndeveloping high-performance predictive models and data-driven solutions. Proficient in harnessing\\nmachine learning to solve complex problems and improve business outcomes. Seeking to apply\\nexpertise in data science and software engineering at an industry-leading tech firm.\\nMachine Learning Engineer Resume\\nEducation\\nM.S. in Computer Science, Specialization in Machine Learning\\nTech University, May 2020\\nThesis: \"Scalable Machine Learning Algorithms for Big Data Environments\"\\nRelevant Coursework: Machine Learning, Predictive Analytics, Data Structures and Algorithms,\\nCloud Computing\\nMachine Learning Engineer Resume\\nWork Experience\\nMachine Learning Engineer, AI Innovations Inc., July 2020 - Present\\n- Led a team to develop a predictive maintenance system that reduced downtime by 30%.\\n- Implemented machine learning models that improved customer recommendation systems,\\nresulting in a 10% uplift in user engagement.\\n- Optimized data processing pipelines in a distributed computing environment, increasing data\\nthroughput by 40%.\\nJunior Data Scientist, DataWise Analytics, June 2018 - June 2020\\n- Assisted in the development of large-scale machine learning models for client projects in retail and\\nfinance sectors.\\n- Conducted exploratory data analysis to identify trends, anomalies, and data-driven insights.\\n- Collaborated with cross-functional teams to integrate machine learning models into production\\nsystems.\\nMachine Learning Engineer Resume\\nSkills\\n- Programming Languages: Proficient in Python, Java, and Scala.\\n- Machine Learning Tools: TensorFlow, PyTorch, scikit-learn, and Keras.\\n- Data Management: Experienced with SQL, NoSQL, Hadoop, and Spark.\\n- DevOps: Familiar with Docker, Kubernetes, and continuous integration/continuous deployment\\n(CI/CD) pipelines.\\n- Soft Skills: Strong communication skills, team leadership, and project management.\\nMachine Learning Engineer Resume\\nCertifications\\nCertified Machine Learning Engineer, ML Certification Institute, 2021\\nData Science Professional Certificate, Coursera, 2019\\nMachine Learning Engineer Resume\\nProjects\\nPredictive Model for Stock Market Trends\\n- Developed a model to predict stock market trends with an accuracy rate of 80%, leveraging time\\nseries analysis and deep learning techniques.\\nCustomer Segmentation Analysis\\n- Conducted a segmentation analysis for a marketing dataset to identify distinct customer groups\\nand inform targeted marketing strategies.\\nMachine Learning Engineer Resume\\nPublications\\nSmith, J., & Doe, A. (2021). \"Enhancing Deep Learning Performance with Advanced Optimization\\nTechniques.\" ML Research Journal, 33(4), 202-210.\\nMachine Learning Engineer Resume\\nProfessional Memberships\\n- Association for Computing Machinery (ACM), Member since 2020\\n- International Association of Machine Learning (IAML), Member since 2021\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "extracted_texts_embeddings={}\n",
    "for key, text in extracted_texts.items():\n",
    "    extracted_texts_embeddings[key] = get_embedding(text, model=\"text-embedding-ada-002\")\n",
    "# extracted_texts_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings = get_embedding(list(new_resume_content.values())[0], model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  PDF File  Similarity Score\n",
      "13  Machine_Learning_Engineer_Resume_5.pdf          0.934206\n",
      "14  Machine_Learning_Engineer_Resume_4.pdf          0.932344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate similarity (cosine similarity) between the resume and each PDF's embedding\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    # Define a function for cosine similarity\n",
    "    dot_product = sum(a*b for a, b in zip(embedding1, embedding2))\n",
    "    norm_a = sum(a*a for a in embedding1) ** 0.5\n",
    "    norm_b = sum(b*b for b in embedding2) ** 0.5\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# Calculate similarities for all PDFs\n",
    "similarities = [calculate_similarity(resume_embeddings, pdf_emb) for pdf_emb in extracted_texts_embeddings.values()]\n",
    "\n",
    "\n",
    "# Create a DataFrame to display these similarities\n",
    "pdf_similarity_df = pd.DataFrame(zip(pdf_filenames, similarities), columns=['PDF File', 'Similarity Score'])\n",
    "\n",
    "# Sort the DataFrame by the similarity score in descending order\n",
    "sorted_pdf_similarity_df = pdf_similarity_df.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame to find the top matches\n",
    "print(sorted_pdf_similarity_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedragenv",
   "language": "python",
   "name": "bedragenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
